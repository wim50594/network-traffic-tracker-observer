[output]
data_path = data

[crawler]
web_pages = lists/crawl/majestic_million.txt
limit_study = 1000
wait_page = 15
scroll = true
timeout = 20
override = true
screenshots = true
pcap = tcpdump.pcap
ssl = sslkeylogfile.txt
accept_words = lists/accept_words.txt
check_accept_words_sim = false
cookie = true
origin_req = true

[docker]
n_container = 3
crawler_image = chrome-crawler
tcpdump_image = kaazing/tcpdump

[preprocess]
filterlist = ['https://easylist.to/easylist/easyprivacy.txt', 'https://easylist.to/easylist/easylist.txt']
save_filterlist = true
ressources = ressources.json
capture = capture.json
keep_capture = false
keep_ressource = false
override = true
collect = {'sizes': 'tcp.len', 'ip_src': 'ip.src', 'ip_dst': 'ip.dst', 'rel_time': 'frame.time_relative'}
cast = {'sizes': int, 'rel_time': float}

[logging]
level = INFO
directory = logs
